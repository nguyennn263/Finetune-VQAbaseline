{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edc31e0",
   "metadata": {},
   "source": [
    "# üöÄ Kaggle Training Instructions\n",
    "\n",
    "## Before running this notebook on Kaggle:\n",
    "\n",
    "1. **Create your dataset** on Kaggle with your images and text data\n",
    "2. **Update the dataset name** in cell 7: Change `DATASET_NAME = 'auto-vivqa'` to your actual dataset name\n",
    "3. **Make sure your dataset structure is**:\n",
    "   ```\n",
    "   /kaggle/input/your-dataset-name/\n",
    "   ‚îú‚îÄ‚îÄ images/images/          # Image files (.jpg, .png)\n",
    "   ‚îî‚îÄ‚îÄ text/text/             # CSV file\n",
    "       ‚îî‚îÄ‚îÄ evaluate_60k_data_balanced_preprocessed.csv\n",
    "   ```\n",
    "4. **Enable GPU** in Kaggle notebook settings (recommended: P100 or T4)\n",
    "5. **Run all cells** sequentially\n",
    "\n",
    "The notebook will automatically:\n",
    "- Clone this repository to `/kaggle/working`\n",
    "- Use the project's configuration system (`get_improved_config()`)\n",
    "- Auto-detect Kaggle environment and apply optimized settings\n",
    "- Update dataset paths automatically\n",
    "- Train the Vietnamese VQA model with the exact same logic as `main.py`\n",
    "- Save results and checkpoints\n",
    "\n",
    "**Note**: The configuration system automatically handles:\n",
    "- Environment detection (Kaggle vs local)\n",
    "- GPU optimization and batch sizing\n",
    "- Learning rates and training parameters\n",
    "- Paths and output directories\n",
    "\n",
    "No manual configuration needed - just update your dataset name!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b959e8c",
   "metadata": {},
   "source": [
    "# Enhanced Vietnamese VQA Training on Kaggle\n",
    "\n",
    "This notebook provides an optimized training pipeline for Vietnamese Visual Question Answering using CLIP, XLM-RoBERTa, and mT5 models.\n",
    "\n",
    "## Features:\n",
    "- Multiple correct answers support\n",
    "- Mixed precision training (AMP)\n",
    "- Gradient accumulation\n",
    "- Memory optimization for Kaggle GPUs\n",
    "- Early stopping and checkpointing\n",
    "- Comprehensive evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682f7e7",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and System Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83804e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Kaggle and setup environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "is_kaggle = os.path.exists('/kaggle')\n",
    "print(f\"Running on Kaggle: {is_kaggle}\")\n",
    "\n",
    "if is_kaggle:\n",
    "    # Change to kaggle working directory\n",
    "    os.chdir('/kaggle/working')\n",
    "    print(\"Working directory:\", os.getcwd())\n",
    "    \n",
    "    # Clone the repository if not already present\n",
    "    if not os.path.exists('Finetune-VQAbaseline'):\n",
    "        print(\"Cloning repository...\")\n",
    "        import subprocess\n",
    "        try:\n",
    "            result = subprocess.run([\n",
    "                'git', 'clone', \n",
    "                'https://github.com/nguyennn263/Finetune-VQAbaseline.git'\n",
    "            ], capture_output=True, text=True, check=True)\n",
    "            print(\"‚úì Repository cloned successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Error cloning repository: {e}\")\n",
    "            print(\"Please manually clone the repo or check the repository URL\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"‚úì Repository already exists\")\n",
    "    \n",
    "    # Change to project directory and add to Python path\n",
    "    os.chdir('Finetune-VQAbaseline')\n",
    "    sys.path.insert(0, '/kaggle/working/Finetune-VQAbaseline')\n",
    "    print(\"Changed to project directory:\", os.getcwd())\n",
    "    \n",
    "else:\n",
    "    print(\"Running locally - using current directory\")\n",
    "    # Add current directory to Python path for local testing\n",
    "    current_dir = os.getcwd()\n",
    "    if current_dir not in sys.path:\n",
    "        sys.path.insert(0, current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if not already installed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package.split('==')[0].replace('-', '_'))\n",
    "        print(f\"‚úì {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package, '--quiet'])\n",
    "\n",
    "# Essential packages for Kaggle\n",
    "required_packages = [\n",
    "    'torch>=2.0.0',\n",
    "    'torchvision>=0.15.0', \n",
    "    'transformers>=4.30.0',\n",
    "    'sentencepiece>=0.1.99',\n",
    "    'rouge_score>=0.1.2',\n",
    "    'nltk>=3.8.0'\n",
    "]\n",
    "\n",
    "for package in required_packages:\n",
    "    install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System information check\n",
    "import torch\n",
    "import os\n",
    "\n",
    "def print_system_info():\n",
    "    \"\"\"Print comprehensive system information\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SYSTEM INFORMATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            gpu_props = torch.cuda.get_device_properties(i)\n",
    "            memory_gb = gpu_props.total_memory / 1e9\n",
    "            print(f\"GPU {i}: {gpu_props.name}\")\n",
    "            print(f\"  Memory: {memory_gb:.1f} GB\")\n",
    "            print(f\"  Compute capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "    \n",
    "    print(f\"CPU count: {os.cpu_count()}\")\n",
    "    print(f\"Available memory: {os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES') / 1e9:.1f} GB\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "print_system_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef56fc5",
   "metadata": {},
   "source": [
    "## 2. Data Setup and Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset path for Kaggle (needed before importing modules)\n",
    "if is_kaggle:\n",
    "    # Define your dataset name here  \n",
    "    DATASET_NAME = 'auto-vivqa'  # ‚ö†Ô∏è CHANGE THIS to your actual Kaggle dataset name\n",
    "    \n",
    "    print(f\"Dataset configuration:\")\n",
    "    print(f\"  Dataset name: {DATASET_NAME}\")\n",
    "    print(f\"  Expected path: /kaggle/input/{DATASET_NAME}\")\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    dataset_path = f'/kaggle/input/{DATASET_NAME}'\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"‚úì Dataset found at {dataset_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Dataset not found at {dataset_path}\")\n",
    "        print(\"Available datasets:\")\n",
    "        if os.path.exists('/kaggle/input'):\n",
    "            for item in os.listdir('/kaggle/input'):\n",
    "                print(f\"  - {item}\")\n",
    "        print(f\"\\nüí° Update DATASET_NAME above to match your dataset\")\n",
    "else:\n",
    "    print(\"Running locally - will use local paths from config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06cdee",
   "metadata": {},
   "source": [
    "## 3. Import and Setup Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and system check (like main.py beginning)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Additional imports for notebook functionality\n",
    "from collections import Counter\n",
    "import gc\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(\"‚úì Basic libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9285add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules exactly like main.py\n",
    "print(\"Importing modules...\")\n",
    "\n",
    "try:\n",
    "    # Import exactly as in main.py\n",
    "    from cxmt5.config import get_improved_config\n",
    "    from cxmt5.model import ImprovedVietnameseVQAModel, normalize_vietnamese_answer\n",
    "    from cxmt5.cxmt5 import VietnameseVQADataset, VietnameseVQAModel, VQATrainer, prepare_data_from_dataframe\n",
    "    from transformers import (\n",
    "        CLIPProcessor, CLIPModel,\n",
    "        XLMRobertaTokenizer, XLMRobertaModel,\n",
    "        T5ForConditionalGeneration, T5Tokenizer,\n",
    "        AutoTokenizer, AutoModel\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Successfully imported all modules\")\n",
    "    print(\"‚úì cxmt5.config imported\")\n",
    "    print(\"‚úì cxmt5.model imported\") \n",
    "    print(\"‚úì cxmt5.cxmt5 imported\")\n",
    "    print(\"‚úì transformers imported\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import modules: {e}\")\n",
    "    print(\"Current working directory:\", os.getcwd())\n",
    "    print(\"Python path:\", sys.path[:3])\n",
    "    \n",
    "    # Debug information\n",
    "    if os.path.exists('cxmt5'):\n",
    "        print(\"Files in cxmt5 directory:\")\n",
    "        for file in os.listdir('cxmt5'):\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(\"‚ùå cxmt5 directory not found!\")\n",
    "        print(\"Available directories:\")\n",
    "        for item in os.listdir('.'):\n",
    "            if os.path.isdir(item):\n",
    "                print(f\"  - {item}/\")\n",
    "    \n",
    "    raise ImportError(\"Cannot import required modules. Please check the repository structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d87edf",
   "metadata": {},
   "source": [
    "## 4. Import Project Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498efe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration (exactly like main.py)\n",
    "print(\"Loading configuration...\")\n",
    "\n",
    "# Get the improved configuration from the project\n",
    "# This will automatically detect Kaggle environment and use appropriate config\n",
    "config = get_improved_config()\n",
    "\n",
    "print(f\"‚úì Configuration loaded successfully\")\n",
    "print(f\"‚úì Environment detected and config applied\")\n",
    "\n",
    "print(f\"\\nConfiguration Summary:\")\n",
    "print(f\"  Device: {config['device']}\")\n",
    "print(f\"  Batch size: {config['batch_size']}\")\n",
    "print(f\"  Epochs: {config['num_epochs']}\")\n",
    "print(f\"  Vision model: {config['vision_model']}\")\n",
    "print(f\"  Text model: {config['text_model']}\")\n",
    "print(f\"  Decoder model: {config['decoder_model']}\")\n",
    "print(f\"  Image directory: {config['image_dir']}\")\n",
    "print(f\"  Text directory: {config['text_dir']}\")\n",
    "print(f\"  Learning rates:\")\n",
    "print(f\"    Decoder: {config['decoder_lr']:.2e}\")\n",
    "print(f\"    Encoder: {config['encoder_lr']:.2e}\")\n",
    "print(f\"    Vision: {config['vision_lr']:.2e}\")\n",
    "print(f\"  Data augmentation: {config.get('use_data_augmentation', False)}\")\n",
    "print(f\"  Wandb logging: {config.get('use_wandb', False)}\")\n",
    "print(f\"  Label smoothing: {config['label_smoothing']}\")\n",
    "print(f\"  Dropout rate: {config['dropout_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2913ec",
   "metadata": {},
   "source": [
    "## 5. Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data and load CSV (using config paths)\n",
    "print(f\"Data verification using config paths:\")\n",
    "print(f\"  Images: {config['image_dir']}\")\n",
    "print(f\"  Text: {config['text_dir']}\")\n",
    "\n",
    "# Check image directory\n",
    "if os.path.exists(config['image_dir']):\n",
    "    image_files = [f for f in os.listdir(config['image_dir']) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    print(f\"‚úì Found {len(image_files):,} images\")\n",
    "else:\n",
    "    print(f\"‚ùå Image directory not found: {config['image_dir']}\")\n",
    "\n",
    "# Check text directory and CSV file\n",
    "csv_file = f'{config[\"text_dir\"]}/evaluate_60k_data_balanced_preprocessed.csv'\n",
    "if os.path.exists(csv_file):\n",
    "    print(f\"‚úì Found CSV file: {csv_file}\")\n",
    "    \n",
    "    # Load and prepare data (same as main.py)\n",
    "    print(f\"Loading data...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"‚úì Loaded CSV with {len(df):,} rows\")\n",
    "    print(f\"‚úì Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nSample data:\")\n",
    "    print(df.head(2))\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå CSV file not found: {csv_file}\")\n",
    "    \n",
    "    # List available files for debugging\n",
    "    if os.path.exists(config[\"text_dir\"]):\n",
    "        print(f\"Available files in {config['text_dir']}:\")\n",
    "        for file in os.listdir(config[\"text_dir\"]):\n",
    "            print(f\"  - {file}\")\n",
    "    raise FileNotFoundError(f\"Required CSV file not found: {csv_file}\")\n",
    "\n",
    "# Prepare questions using the same function as main.py\n",
    "print(f\"Preparing questions...\")\n",
    "questions = prepare_data_from_dataframe(df)\n",
    "print(f\"‚úì Prepared {len(questions):,} questions\")\n",
    "\n",
    "# Show sample (same as main.py)\n",
    "if questions:\n",
    "    sample = questions[0]\n",
    "    print(f\"\\nSample question: {sample['question']}\")\n",
    "    print(f\"Sample answer: {sample['ground_truth']}\")\n",
    "    if 'all_correct_answers' in sample:\n",
    "        print(f\"All correct answers: {sample['all_correct_answers']}\")\n",
    "else:\n",
    "    raise ValueError(\"No questions were prepared from the dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2466be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data balance analysis (same as main.py)\n",
    "def analyze_data_balance(questions):\n",
    "    \"\"\"Analyze answer distribution for balance with multiple answers support\"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Collect all answers (including all 5 per question)\n",
    "    all_answers = []\n",
    "    for q in questions:\n",
    "        if 'all_correct_answers' in q and q['all_correct_answers']:\n",
    "            # Add all 5 correct answers\n",
    "            all_answers.extend([normalize_vietnamese_answer(ans) for ans in q['all_correct_answers']])\n",
    "        else:\n",
    "            # Fallback to ground_truth\n",
    "            all_answers.append(normalize_vietnamese_answer(q['ground_truth']))\n",
    "    \n",
    "    answer_counts = Counter(all_answers)\n",
    "    \n",
    "    print(f\"\\nData Balance Analysis (Multiple Answers):\")\n",
    "    print(f\"  Total questions: {len(questions):,}\")\n",
    "    print(f\"  Total answer instances: {len(all_answers):,}\")\n",
    "    print(f\"  Average answers per question: {len(all_answers) / len(questions):.2f}\")\n",
    "    print(f\"  Unique answers: {len(answer_counts):,}\")\n",
    "    print(f\"  Top 10 most common answers:\")\n",
    "    \n",
    "    for answer, count in answer_counts.most_common(10):\n",
    "        percentage = (count / len(all_answers)) * 100\n",
    "        print(f\"    '{answer}': {count} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Check for severe imbalance\n",
    "    most_common_count = answer_counts.most_common(1)[0][1]\n",
    "    imbalance_ratio = most_common_count / len(all_answers)\n",
    "    \n",
    "    if imbalance_ratio > 0.2:  # Lower threshold for multiple answers\n",
    "        print(f\"Severe imbalance detected: {imbalance_ratio:.2f} of answers are the same\")\n",
    "    else:\n",
    "        print(f\"Data balance looks good: {imbalance_ratio:.2f}\")\n",
    "\n",
    "    return answer_counts\n",
    "\n",
    "# Run the analysis\n",
    "answer_counts = analyze_data_balance(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aef9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd1f5e",
   "metadata": {},
   "source": [
    "## 7. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizers and processors\n",
    "print(\"Loading tokenizers and processors...\")\n",
    "\n",
    "question_tokenizer = XLMRobertaTokenizer.from_pretrained(config['text_model'])\n",
    "answer_tokenizer = T5Tokenizer.from_pretrained(config['decoder_model'], legacy=False)\n",
    "clip_processor = CLIPProcessor.from_pretrained(config['vision_model'])\n",
    "\n",
    "print(\"‚úì Tokenizers and processors loaded\")\n",
    "\n",
    "# Test tokenization\n",
    "sample_question = train_questions[0]['question']\n",
    "sample_answer = train_questions[0]['ground_truth']\n",
    "\n",
    "print(f\"\\nTesting tokenization:\")\n",
    "print(f\"  Question: '{sample_question}'\")\n",
    "print(f\"  Answer: '{sample_answer}'\")\n",
    "\n",
    "q_tokens = question_tokenizer(sample_question, max_length=config['max_length'], \n",
    "                             truncation=True, padding='max_length', return_tensors='pt')\n",
    "a_tokens = answer_tokenizer(sample_answer, max_length=config['max_length'], \n",
    "                           truncation=True, padding='max_length', return_tensors='pt')\n",
    "\n",
    "print(f\"  Question tokens shape: {q_tokens['input_ids'].shape}\")\n",
    "print(f\"  Answer tokens shape: {a_tokens['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "\n",
    "try:\n",
    "    train_dataset = VietnameseVQADataset(\n",
    "        train_questions, config['image_dir'], question_tokenizer,\n",
    "        answer_tokenizer, clip_processor, config['max_length']\n",
    "    )\n",
    "    \n",
    "    val_dataset = VietnameseVQADataset(\n",
    "        val_questions, config['image_dir'], question_tokenizer,\n",
    "        answer_tokenizer, clip_processor, config['max_length']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Datasets created successfully\")\n",
    "    print(f\"  Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"  Val dataset size: {len(val_dataset)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating datasets: {e}\")\n",
    "    print(\"This likely means the cxmt5 module is not available.\")\n",
    "    print(\"Please ensure your cxmt5 module is included in the Kaggle dataset.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f86b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "print(\"Creating data loaders...\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config.get('num_workers', 0),\n",
    "    pin_memory=config.get('pin_memory', False),\n",
    "    persistent_workers=config.get('persistent_workers', False) and config.get('num_workers', 0) > 0,\n",
    "    drop_last=config.get('dataloader_drop_last', True)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 0),\n",
    "    pin_memory=config.get('pin_memory', False),\n",
    "    persistent_workers=config.get('persistent_workers', False) and config.get('num_workers', 0) > 0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"‚úì Data loaders created\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Effective batch size: {config['batch_size'] * config.get('accumulation_steps', 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing model...\")\n",
    "\n",
    "try:\n",
    "    model = ImprovedVietnameseVQAModel(config)\n",
    "    model = model.to(config['device'])\n",
    "    \n",
    "    print(\"‚úì Model initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing model: {e}\")\n",
    "    print(\"This likely means the cxmt5 module is not available.\")\n",
    "    raise\n",
    "\n",
    "# Model statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"  Trainable ratio: {trainable_params/total_params:.2%}\")\n",
    "\n",
    "# Memory usage\n",
    "if config['device'] == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    memory_allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    memory_reserved = torch.cuda.memory_reserved() / 1e9\n",
    "    print(f\"\\nGPU Memory:\")\n",
    "    print(f\"  Allocated: {memory_allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {memory_reserved:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94068827",
   "metadata": {},
   "source": [
    "## 8. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model forward pass\n",
    "print(\"Testing model forward pass...\")\n",
    "\n",
    "try:\n",
    "    # Get a test batch\n",
    "    test_batch = next(iter(train_loader))\n",
    "    \n",
    "    # Move to device\n",
    "    for key, value in test_batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            test_batch[key] = value.to(config['device'])\n",
    "    \n",
    "    # Test with smaller batch for memory efficiency\n",
    "    batch_size = min(2, test_batch['pixel_values'].size(0))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            pixel_values=test_batch['pixel_values'][:batch_size],\n",
    "            question_input_ids=test_batch['question_input_ids'][:batch_size],\n",
    "            question_attention_mask=test_batch['question_attention_mask'][:batch_size],\n",
    "            answer_input_ids=test_batch['answer_input_ids'][:batch_size],\n",
    "            answer_attention_mask=test_batch['answer_attention_mask'][:batch_size]\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Forward pass successful\")\n",
    "        print(f\"  Loss: {outputs.loss.item():.4f}\")\n",
    "        print(f\"  Logits shape: {outputs.logits.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in forward pass: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Clean up memory\n",
    "    if config['device'] == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inference mode\n",
    "print(\"Testing inference mode...\")\n",
    "\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model(\n",
    "            pixel_values=test_batch['pixel_values'][:1],\n",
    "            question_input_ids=test_batch['question_input_ids'][:1],\n",
    "            question_attention_mask=test_batch['question_attention_mask'][:1]\n",
    "        )\n",
    "        \n",
    "        pred_text = model.decoder_tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        try:\n",
    "            clean_pred_text = model.clean_generated_text(pred_text)\n",
    "        except:\n",
    "            clean_pred_text = pred_text.strip()\n",
    "        \n",
    "        print(f\"‚úì Inference successful\")\n",
    "        print(f\"  Sample prediction (raw): '{pred_text}'\")\n",
    "        print(f\"  Sample prediction (clean): '{clean_pred_text}'\")\n",
    "        print(f\"  Sample ground truth: '{test_batch['answer_text'][0]}'\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in inference: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Clean up memory\n",
    "    if config['device'] == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    raise\n",
    "\n",
    "# Clean up test batch\n",
    "del test_batch\n",
    "gc.collect()\n",
    "if config['device'] == 'cuda':\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a342e",
   "metadata": {},
   "source": [
    "## 9. Training Setup and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f748b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer (same as main.py)\n",
    "print(f\"Initializing VQA trainer...\")\n",
    "\n",
    "try:\n",
    "    trainer = VQATrainer(model, train_loader, val_loader, torch.device(config['device']), config)\n",
    "    print(\"‚úì Trainer initialized successfully\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing trainer: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "# Display training configuration (same as main.py)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ENHANCED TRAINING CONFIGURATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training for {config['num_epochs']} epochs with:\")\n",
    "print(f\"  Decoder LR: {config['decoder_lr']:.2e}\")\n",
    "print(f\"  Encoder LR: {config['encoder_lr']:.2e}\")\n",
    "print(f\"  Vision LR: {config['vision_lr']:.2e}\")\n",
    "print(f\"  Label smoothing: {config['label_smoothing']}\")\n",
    "print(f\"  Dropout rate: {config['dropout_rate']}\")\n",
    "print(f\"  Warmup ratio: {config.get('warmup_ratio', 0.1)}\")\n",
    "print(f\"  Data augmentation: {config.get('use_data_augmentation', False)}\")\n",
    "print(f\"  Wandb logging: {config.get('use_wandb', False)}\")\n",
    "print(f\"Dataset: {len(train_questions):,} train, {len(val_questions):,} val\")\n",
    "print(f\"Batch size: {config['batch_size']}\")\n",
    "print(f\"Device: {config['device']}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (same style as main.py)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STARTING ENHANCED TRAINING\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    best_accuracy = trainer.train(config['num_epochs'])\n",
    "    \n",
    "    training_time = (time.time() - start_time) / 3600  # hours\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training time: {training_time:.2f} hours\")\n",
    "    print(f\"Best fuzzy accuracy achieved: {best_accuracy:.4f}\")\n",
    "    print(f\"Model and checkpoints saved in current directory\")\n",
    "    print(f\"Predictions saved for analysis\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nTraining interrupted by user\")\n",
    "    print(f\"Saving current state...\")\n",
    "    try:\n",
    "        trainer.save_checkpoint(trainer.global_step // len(train_loader), {}, is_best=False)\n",
    "        print(f\"‚úì Checkpoint saved\")\n",
    "    except Exception as save_error:\n",
    "        print(f\"‚ùå Error saving checkpoint: {save_error}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError during training: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Try to save emergency checkpoint\n",
    "    try:\n",
    "        emergency_path = f\"{config['output_dir']}/emergency_checkpoint.pt\"\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'config': config,\n",
    "            'error': str(e)\n",
    "        }, emergency_path)\n",
    "        print(f\"Emergency checkpoint saved to: {emergency_path}\")\n",
    "    except Exception as emergency_error:\n",
    "        print(f\"Failed to save emergency checkpoint: {emergency_error}\")\n",
    "\n",
    "finally:\n",
    "    # Clean up memory\n",
    "    if config['device'] == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    total_time = (time.time() - start_time) / 3600\n",
    "    print(f\"\\nTotal execution time: {total_time:.2f} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c2fe0",
   "metadata": {},
   "source": [
    "## 10. Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98260068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved files\n",
    "print(\"Checking saved files...\")\n",
    "\n",
    "output_files = []\n",
    "if os.path.exists(config['output_dir']):\n",
    "    for file in os.listdir(config['output_dir']):\n",
    "        file_path = os.path.join(config['output_dir'], file)\n",
    "        file_size = os.path.getsize(file_path) / 1e6  # MB\n",
    "        output_files.append((file, file_size))\n",
    "        print(f\"  {file}: {file_size:.1f} MB\")\n",
    "\n",
    "if os.path.exists(config['checkpoint_dir']):\n",
    "    print(f\"\\nCheckpoints in {config['checkpoint_dir']}:\")\n",
    "    for file in os.listdir(config['checkpoint_dir']):\n",
    "        file_path = os.path.join(config['checkpoint_dir'], file)\n",
    "        file_size = os.path.getsize(file_path) / 1e6  # MB\n",
    "        print(f\"  {file}: {file_size:.1f} MB\")\n",
    "\n",
    "# Check for predictions file\n",
    "predictions_file = f\"{config['output_dir']}/predictions.json\"\n",
    "if os.path.exists(predictions_file):\n",
    "    print(f\"\\n‚úì Predictions file found: {predictions_file}\")\n",
    "    \n",
    "    # Load and show sample predictions\n",
    "    try:\n",
    "        import json\n",
    "        with open(predictions_file, 'r', encoding='utf-8') as f:\n",
    "            predictions = json.load(f)\n",
    "        \n",
    "        print(f\"  Total predictions: {len(predictions)}\")\n",
    "        \n",
    "        if predictions:\n",
    "            print(f\"\\nSample predictions:\")\n",
    "            for i, pred in enumerate(predictions[:3]):\n",
    "                print(f\"  {i+1}. Question: {pred.get('question', 'N/A')[:100]}...\")\n",
    "                print(f\"     Prediction: {pred.get('prediction', 'N/A')}\")\n",
    "                print(f\"     Ground Truth: {pred.get('ground_truth', 'N/A')}\")\n",
    "                print(f\"     Correct: {pred.get('correct', 'N/A')}\")\n",
    "                print()\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading predictions: {e}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No predictions file found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae99153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final memory cleanup and summary\n",
    "print(\"\\nCleaning up memory...\")\n",
    "\n",
    "# Delete large objects\n",
    "try:\n",
    "    del model\n",
    "    del trainer  \n",
    "    del train_loader\n",
    "    del val_loader\n",
    "    del train_dataset\n",
    "    del val_dataset\n",
    "except:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if config['device'] == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    final_memory = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"Final GPU memory: {final_memory:.2f} GB\")\n",
    "\n",
    "print(\"\\nüèÅ Notebook execution completed!\")\n",
    "print(f\"Results saved to: {config['output_dir']}\")\n",
    "print(\"You can now download the model and checkpoints from Kaggle.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
